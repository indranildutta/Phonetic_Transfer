primary_data <- read.delim("../Assamese Coronals - Aanusha/Praat_readings/vandana_praatoutput.txt", stringsAsFactors=F)
primary_data <- read.delim("/Assamese Coronals - Aanusha/Praat_readings/vandana_praatoutput.txt", stringsAsFactors=F)
primary_data <- read.delim("/Praat_readings/vandana_praatoutput.txt", stringsAsFactors=F)
vandana_praatoutput <- read.delim("~/Dropbox/Assamese Coronals - Aanusha/Praat_readings/vandana_praatoutput.txt")
View(vandana_praatoutput)
primary_data <- vandana_praatoutput.txt
vandana_praatoutput <- read.delim("~/Dropbox/Assamese Coronals - Aanusha/Praat_readings/vandana_praatoutput.txt")
View(vandana_praatoutput)
attach(vandana_praatoutput)
n= length(vandana_praatoutput$File)
cons = vandana_praatoutput$Consonant
vowel = vandana_praatoutput$Vowel
voiced_cons_list <- c('b','d', 'g')
unvoiced_cons_list <- c('p','t','k')
voiced_cons_dur=vector(mode="double",length=0)
unvoiced_cons_dur=vector(mode="double",length=0)
voiced_cons_back_vow_dur=vector(mode="double",length=0)
voiced_cons_front_vow_dur=vector(mode="double",length=0)
unvoiced_cons_back_vow_dur=vector(mode="double",length=0)
unvoiced_cons_front_vow_dur=vector(mode="double",length=0)
for (i in 1:n){
if (cons[i] %in% voiced_cons_list){
voiced_cons_dur=append(voiced_cons_dur,vandana_praatoutput$Consonant.Dur[i])
} else {
unvoiced_cons_dur=append(unvoiced_cons_dur,vandana_praatoutput$Consonant.Dur[i])
}
}
cat("Mean of voiced consonant durations:",mean(voiced_cons_dur),'\n')
cat("Mean of unvoiced consonant durations:",mean(unvoiced_cons_dur),'\n')
for (i in 1:n){
if (cons[i] %in% voiced_cons_list && vowel[i] == 'u'){
voiced_cons_back_vow_dur=append(voiced_cons_back_vow_dur,vandana_praatoutput$Consonant.Dur[i])
} else if (cons[i] %in% voiced_cons_list && vowel[i] == 'i') {
voiced_cons_front_vow_dur=append(voiced_cons_front_vow_dur,vandana_praatoutput$Consonant.Dur[i])
} else if (cons[i] %in% unvoiced_cons_list && vowel[i] == 'u'){
unvoiced_cons_back_vow_dur=append(unvoiced_cons_back_vow_dur,vandana_praatoutput$Consonant.Dur[i])
} else if (cons[i] %in% unvoiced_cons_list){
unvoiced_cons_front_vow_dur=append(unvoiced_cons_front_vow_dur,vandana_praatoutput$Consonant.Dur[i])
}
}
cat("Mean duration of voiced consonants followed by front vowel:",mean(voiced_cons_front_vow_dur),'\n')
cat("Mean duration of voiced consonants followed by back vowel:",mean(voiced_cons_back_vow_dur),'\n')
cat("Mean duration of unvoiced consonants followed by front vowel:",mean(unvoiced_cons_front_vow_dur),'\n')
cat("Mean duration of unvoiced consonants followed by back vowel:",mean(unvoiced_cons_back_vow_dur),'\n')
View(vandana_praatoutput)
LE = lmer(F2_onset ~ F2_mid + voiced_cons_list, data= vandana_praatoutput)
install.packages("lme4")
Event.Registration <- read.csv("~/Desktop/Event Registration.csv")
View(Event.Registration)
data = c(2,1,6,8,12,5,1,0,1)#c function to catenate individual values together
data
round(rnorm(36,4.5,2))
round(rnorm(36,4.5,2))
data_norm = round(rnorm(36,4.5,2))
data_norm
round(rnorm(36,4.5,2))
round(rnorm(36,4.5,2))
data_norm
rnorm(36,4.5,2)
plot(rating,data,type = "b", main="Sentence rating frequency distribution", xlab = "Rating", ylab = "Frequency")
#data_norm = round(rnorm(36,4.5,2))
rating = c(1,2,3,4,5,6,7,8,9)
plot(rating,data,type = "b", main="Sentence rating frequency distribution", xlab = "Rating", ylab = "Frequency")
rnorm(36,4.5,2)
rating=rnorm(36,4.5,2)
plot(rating,data,type = "b", main="Sentence rating frequency distribution", xlab = "Rating", ylab = "Frequency")
hist(rating)
rating=rnorm(36,4.5,2)
rating
hist(rating)
hist(rating, bin=100)
rating=rnorm(36,4.5,2)
rating
attach(bengali_phon_acco_raw)
x1=round(rnorm(36,4.5,2)) #Generating a small dataset; with N, mean and stdev
x2=round(rnorm(36,4.5,2))
library(ggplot2)
data = c(2,1,6,8,12,5,1,0,1)#c function to catenate individual values together
rating = c(1,2,3,4,5,6,7,8,9)
plot(rating,data,type = "b", main="Sentence rating frequency distribution", xlab = "Rating", ylab = "Frequency")
x = rnorm(36, 4.5, 2)#notice that this is different from round(rnorm(36,4.5,2)) where we had asked for rounded/integer values
#Histograms
histogram=hist(x,breaks=30000, xlim = c(0,10))
hist(x, xlim = c(0,10))
x = rnorm(10000, 4.5, 2)
hist(x,breaks=100,freq=FALSE,xlim = c(0,10))
plot(function(x)dnorm(x, mean=4.5, sd=2), 0,10, add=TRUE)
#Cherokee data
vot01 = c(84, 82, 72,193, 129, 77, 72, 81, 45, 74, 102, 77, 187, 79, 86, 59, 74, 63, 75, 70, 106, 54, 49, 56, 58, 97)
vot71 =c(67, 127, 79, 150, 53, 65, 75, 109, 109, 126, 129, 119, 104, 153, 124, 107, 181, 166)
mean(vot01)#mean of the data set vot01, 84.65385
mean(vot71)#mean of the data set vot71, 113.5
sd(vot01)
summary(vot01)
sd(vot71)# We will get 36.08761 and 35.92844, respectively
hist(vot01,freq=FALSE)#make a histogram by using probability densities and not the actual counts; this way the total area of the histogram is equal to 1
plot(function(x)dnorm(x, mean=84.654, sd=36.088), 40, 200, add=TRUE)#For 2001
vot71.qq = qqnorm(vot71)$x # make the quantile/quantile plot
qqline(vot71) # put the line on the plot
cor(vot71,vot71.qq) # compute the correlation
#t-tests
#One sample
t.test(vot01,mu=100, alternative="less")
attach(F1_data)
F1_data <- read.delim("~/Dropbox/LS175-QuantLing/Johnson_Rscripts/2patterns_tests/F1_data.txt")
View(F1_data)
attach(F1_data)
F1_data
#F1 data from language Ndumbea (subsetting)
F1_data_Ndumbea = F1_data[which(F1_data$language=="Ndumbea"),]
F1_data_Ndumbea
#Correlations
x=F1_data$female
y=F1_data$male
cor(x,y)
summary(f1data)
summary(F1_data)
attach(F1_data)# Don’t have to type f1data$female all the time
plot(female, male)
lines(x=c(mean(x),mean(x)),y=c(200,900),lty=2) lines(x=c(200,1100),y=c(mean(y),mean(y)),lty=2)
lines(x=c(mean(x),mean(x)),y=c(200,900),lty=2) lines(x=c(200,1100),y=c(mean(y),mean(y)),lty=2)
plot(female,male)
attach(F1_data)
clear
x1=round(rnorm(36,4.5,2)) #Generating a small dataset; with N, mean and stdev
x1=round(rnorm(36,4.5,2)) #Generating a small dataset; with N, mean and stdev
x2=round(rnorm(36,4.5,2))
x1=round(rnorm(36,4.5,2)) #Generating a small dataset; with N, mean and stdev
x2=round(rnorm(36,4.5,2))
library(ggplot2)
data = c(2,1,6,8,12,5,1,0,1)#c function to catenate individual values together
rating = c(1,2,3,4,5,6,7,8,9)
plot(rating,data,type = "b", main="Sentence rating frequency distribution", xlab = "Rating", ylab = "Frequency")
x = rnorm(36, 4.5, 2)#notice that this is different from round(rnorm(36,4.5,2)) where we had asked for rounded/integer values
#Histograms
histogram=hist(x,breaks=30000, xlim = c(0,10))
hist(x, xlim = c(0,10))
x = rnorm(10000, 4.5, 2)
hist(x,breaks=100,freq=FALSE,xlim = c(0,10))
plot(function(x)dnorm(x, mean=4.5, sd=2), 0,10, add=TRUE)
#Cherokee data
vot01 = c(84, 82, 72,193, 129, 77, 72, 81, 45, 74, 102, 77, 187, 79, 86, 59, 74, 63, 75, 70, 106, 54, 49, 56, 58, 97)
vot71 =c(67, 127, 79, 150, 53, 65, 75, 109, 109, 126, 129, 119, 104, 153, 124, 107, 181, 166)
mean(vot01)#mean of the data set vot01, 84.65385
mean(vot71)#mean of the data set vot71, 113.5
sd(vot01)
summary(vot01)
sd(vot71)# We will get 36.08761 and 35.92844, respectively
hist(vot01,freq=FALSE)#make a histogram by using probability densities and not the actual counts; this way the total area of the histogram is equal to 1
plot(function(x)dnorm(x, mean=84.654, sd=36.088), 40, 200, add=TRUE)#For 2001
vot71.qq = qqnorm(vot71)$x # make the quantile/quantile plot
qqline(vot71) # put the line on the plot
cor(vot71,vot71.qq) # compute the correlation
#t-tests
#One sample
t.test(vot01,mu=100, alternative="less")
attach(F1_data)
F1_data
#F1 data from language Ndumbea (subsetting)
F1_data_Ndumbea = F1_data[which(F1_data$language=="Ndumbea"),]
F1_data_Ndumbea
#Correlations
x=F1_data$female
y=F1_data$male
cor(x,y)
summary(F1_data)
attach(F1_data)# Don’t have to type f1data$female all the time
plot(female,male)
lines(x=c(mean(x),mean(x)),y=c(200,900),lty=2) lines(x=c(200,1100),y=c(mean(y),mean(y)),lty=2)
x1
View(x1)
x2=round(rnorm(36,4.5,2))
library(ggplot2)
library(lme4)
data = c(2,1,6,8,12,5,1,0,1)#c function to catenate individual values together
rating = c(1,2,3,4,5,6,7,8,9)
plot(rating,data,type = "b", main="Sentence rating frequency distribution", xlab = "Rating", ylab = "Frequency")
x = rnorm(36, 4.5, 2)#notice that this is different from round(rnorm(36,4.5,2)) where we had asked for rounded/integer values
#Histograms
histogram=hist(x,breaks=30000, xlim = c(0,10))
x
histogram
hist(x, xlim = c(0,10))
x = rnorm(10000, 4.5, 2)
hist(x,breaks=100,freq=FALSE,xlim = c(0,10))
plot(function(x)dnorm(x, mean=4.5, sd=2), 0,10, add=TRUE)
#Cherokee data
vot01 = c(84, 82, 72,193, 129, 77, 72, 81, 45, 74, 102, 77, 187, 79, 86, 59, 74, 63, 75, 70, 106, 54, 49, 56, 58, 97)
vot71 =c(67, 127, 79, 150, 53, 65, 75, 109, 109, 126, 129, 119, 104, 153, 124, 107, 181, 166)
mean(vot01)#mean of the data set vot01, 84.65385
mean(vot71)#mean of the data set vot71, 113.5
sd(vot01)
summary(vot01)
plot(function(x)dnorm(x, mean=4.5, sd=2), 0,10, add=TRUE)
plot(function(x)dnorm(x, mean=4.5, sd=2), 0,10, add=TRUE)
hist(x,breaks=100,freq=FALSE,xlim = c(0,10))
plot(function(x)dnorm(x, mean=4.5, sd=2), 0,10, add=TRUE)
#Histograms
histogram=hist(x,breaks=30000, xlim = c(0,10))
#Histograms
histogram=hist(x,breaks=30000, xlim = c(0,10))
plot(function(x)dnorm(x, mean=4.5, sd=2), 0,10, add=TRUE)
#Cherokee data
vot01 = c(84, 82, 72,193, 129, 77, 72, 81, 45, 74, 102, 77, 187, 79, 86, 59, 74, 63, 75, 70, 106, 54, 49, 56, 58, 97)
vot71 =c(67, 127, 79, 150, 53, 65, 75, 109, 109, 126, 129, 119, 104, 153, 124, 107, 181, 166)
mean(vot01)#mean of the data set vot01, 84.65385
mean(vot71)#mean of the data set vot71, 113.5
sd(vot01)
summary(vot01)
sd(vot71)# We will get 36.08761 and 35.92844, respectively
hist(vot01,freq=FALSE)#make a histogram by using probability densities and not the actual counts; this way the total area of the histogram is equal to 1
plot(function(x)dnorm(x, mean=84.654, sd=36.088), 40, 200, add=TRUE)#For 2001
plot(sin, -pi, 2*pi) # see ?plot.function
plot(sin, pi, 2*pi) # see ?plot.function
plot(function(x)dnorm(x, mean=84.654, sd=36.088), 40, 200, add=TRUE)#For 2001
vot71.qq = qqnorm(vot71)$x # make the quantile/quantile plot
qqline(vot71) # put the line on the plot
cor(vot71,vot71.qq) # compute the correlation
#t-tests
#One sample
t.test(vot01,mu=100, alternative="less")
F1_data <- read.delim("~/Dropbox/LS175-QuantLing/Johnson_Rscripts/2patterns_tests/F1_data.txt")
View(F1_data)
attach(F1_data)
F1_data
#F1 data from language Ndumbea (subsetting)
F1_data_Ndumbea = F1_data[which(F1_data$language=="Ndumbea"),]
F1_data_Ndumbea
#Correlations
x=F1_data$female
y=F1_data$male
cor(x,y)
summary(F1_data)
attach(F1_data)# Don’t have to type f1data$female all the time
plot(female,male)
dict_word_syll - c(1, 2, 3, 4, 5)
dict_word_syll = c(1, 2, 3, 4, 5)
summary(dict_word_syll)
x1=round(rnorm(25,75,8)
x1=round(rnorm(25,75,8)
x1=round(rnorm(25,75,8))
x1
t.test(x1,mu=100, alternative="less")
x1=round(rnorm(25,75,12))
t.test(x1,mu=100, alternative="less")
x1=round(rnorm(25,75,12))
t.test(x1,mu=100, alternative="more")
t.test(x1,mu=100, alternative="greater")
x1=round(rnorm(25,80,12))
t.test(x1,mu=100, alternative="less")
x1=round(rnorm(25,90,12))
t.test(x1,mu=100, alternative="less")
x1
t.test(x1,mu=100, alternative="less")
,
#t-tests
#One sample
M1_Duration = c(56, 83, 100,  91,  87,  87, 110,  93, 105,  99,  75,  81, 107,  82,  99,  86,  86, 115,  85,  90,  95,  86,  92,  94,  81)
#t-tests
#One sample
M1_Duration = c(56, 83, 100,  91, 87, 87, 110, 93, 105,  99,  75,  81, 107,  82,  99,  86,  86, 115,  85,  90,  95,  86,  92, 94, 81)
mean(M1_Duration)
sd(M1_Duration)
t.test(M1_Duration,mu=100, alternative="less")
knitr::opts_chunk$set(echo = FALSE)
summary(cars)
plot(pressure)
## Structural elements that make up sound segments and higher order representations
## Sounds of the World's Languages
-[Interactive IPA chart](https://www.ipachart.com/)
-Resources
[A course in Phonetics by Peter Ladefoged](http://www.phonetics.ucla.edu/course/contents.html)
[Vowels and Consonants by Peter Ladefoged](http://www.phonetics.ucla.edu/vowels/contents.html)
devtools::install_github("datalorax/slidex")
devtools::install_github("datalorax/slidex")
formant_data_5 <- read.csv("formant_data_5.csv")
setwd("~/Phonetic_Transfer/RCode")
formant_data_5 <- read.csv("formant_data_5.csv")
attach(formant_data_5)
detach(formant_data_5)
library(lattice)
library(plyr)
library(phonR)
library(lme4)
library(lme4)
library(ggplot2)
library(dplyr)
library(tidyr)
library(stargazer)
?gather
normF1 <- with(formant_data_5,normLobanov(cbind(F1_5,F1_15,F1_25,F1_35,F1_45)),group=Subject)
normF1 <- as.data.frame(normF1)
normF2 <- with(formant_data_5,normLobanov(cbind(F2_5,F2_15,F2_25,F2_35,F2_45)),group=Subject)
normF2 <- as.data.frame(normF2)
with(formant_data_5, plotVowels(normF1$F1_15, normF2$F2_15, Vowel, group = Context, plot.tokens = FALSE,
plot.means = TRUE , var.sty.by = Vowel,var.col.by = Context, pch.means = Vowel, cex.tokens = 0.8,
cex.means = 0.8, alpha.means = 0.3,alpha.tokens = 0.3,ellipse.line = TRUE,  ellipse.fill = TRUE,
fill.opacity = 0.1, pretty = TRUE))
## bengali baseline data
bengali <- read.csv("~/Desktop/Disha_Project/bengali_shruti/anti.csv", stringsAsFactors = TRUE, header = TRUE)
## bengali baseline data
bengali <- read.csv("anti.csv", stringsAsFactors = TRUE, header = TRUE)
attach(bengali)
detach(bengali)
bengaliAE <- subset (bengali, V1=="A"|V1=="E")
attach(bengaliAE)
detach(bengaliAE)
bengaliAE_bd
#subset by context
contexte <- formant_data_5[formant_data_5$Context=="e",]
contexte <- droplevels(contexte)
attach(contexte)
enormF1 <- with(contexte,normLobanov(cbind(F1_5,F1_15,F1_25,F1_35,F1_45)),group=Subject)
enormF1 <- as.data.frame(enormF1)
boxplot(enormF1$F1_25 ~ Vowel*Subject, las = 2, ylab = "Lobanov-normalized F1")
detach(contexte)
contexte_vt <- formant_data_5[formant_data_5$Context=="e" & formant_data_5$Vowel=="\\vt",]
contexte_vt <- droplevels(contexte_vt)
evt_normF1 <- with(contexte_vt,normLobanov(cbind(F1_5,F1_15,F1_25,F1_35,F1_45)),group=Subject)
evt_normF1 <- as.data.frame(evt_normF1)
evt_normF2 <- with(contexte_vt,normLobanov(cbind(F2_5,F2_15,F2_25,F2_35,F2_45)),group=Subject)
evt_normF2 <- as.data.frame(evt_normF2)
bengaliA <- subset (bengali, V1=="A")
ben_f1A <- with(bengaliA, mean(bengaliA$F1_V1_T55))
ben_f2A <- with(bengaliA, mean(bengaliA$F2_V1_T55))
eng_f1vt <- mean(evt_normF1$F1_45, na.rm = TRUE)
eng_f2vt <- mean(evt_normF2$F2_45, na.rm = TRUE)
taskp <- formant_data_5[formant_data_5$Task=="p",]
taskp <- droplevels(taskp)
attach(taskp)
pnormF1 <- with(taskp,normLobanov(cbind(F1_5,F1_15,F1_25,F1_35,F1_45)),group=Subject)
pnormF1 <- as.data.frame(pnormF1)
p_phon_acco.model = lmer(pnormF1$F1_5 ~ Gender + Vowel*Context + (1+Context|Word), data=taskp, REML=FALSE)
p_null.model = lmer(pnormF1$F1_5 ~ Gender + (1+Context|Word), data=taskp, REML=FALSE)
summary(p_phon_acco.model)
summary(p_null.model)
anova(p_phon_acco.model,p_null.model)
boxplot(pnormF1$F1_5~Context*Vowel)
detach(taskp)
# subject-wise F1 in English context
attach(contexte)
ggplot(contexte, aes(x = Subject, y = enormF1$F1_25, fill = Vowel)) + ylab("Normalized F1") +geom_boxplot()
detach(contexte)
# vowels: unilingual English, mixed, and baseline Bengali
xlim <- c(3,-3)
ylim = c(3,-3)
remapping <- c(A = "a:", E = "\\ae")
bengaliAE$unicodevowel <- remapping[as.character(bengaliAE$V1)]
with(bengaliAE,plotVowels(F1_V1_T55,F2_V1_T55, unicodevowel, plot.tokens = F, plot.means = TRUE,
pch.tokens = V1, pch.means = unicodevowel, cex.tokens = 0.8, var.col.by = V1,
cex.means = 0.8, alpha.means = 0.8,alpha.tokens = 0.1,ellipse.line = F,
ellipse.fill = T, pretty = TRUE, xlim = xlim, ylim = ylim, axes=FALSE))
par(new = TRUE)
with(formant_data_5, plotVowels(normF1$F1_45, normF2$F2_45, Vowel, group = Context, plot.tokens = FALSE,
plot.means = TRUE , var.sty.by = Context, pch.means = Vowel, cex.tokens = 0.8,
cex.means = 0.8, alpha.means = 0.5,alpha.tokens = 0.3,ellipse.line = T,  ellipse.fill = T,
fill.opacity = 0.1, pretty = TRUE, xlim = xlim, ylim = ylim))
## main model
phon_acco.model = lmer(normF1$F1_25 ~ Gender + Context*Vowel + Task + (1+Task+Context|Word) +
(1+Task+Context*Vowel|Subject), data=formant_data_5, REML=FALSE)
summary(phon_acco.model)
null.model = lmer(normF1$F1_25 ~ Gender + Context*Vowel + Task + (1+Task+Context|Word) +
(1+Task+Context+Vowel|Subject), data=formant_data_5, REML=FALSE)
anova(phon_acco.model,null.model)
coef(phon_acco.model)
boxplot(normF1$F1_25~ Vowel*Subject,las=2)
## output for writeup: F1
phon_acco.model5 = lmer(normF1$F1_5 ~ Gender + Context*Vowel + Task + (1+Task+Context|Word) +
(1+Task+Context*Vowel|Subject), data=formant_data_5, REML=FALSE)
null.model5 = lmer(normF1$F1_5 ~ Gender + Task + (1+Task+Context|Word) +
(1+Task+Context*Vowel|Subject), data=formant_data_5, REML=FALSE)
null.model15 = lmer(normF1$F1_15 ~ Gender + Task + (1+Task+Context|Word) +
(1+Task+Context*Vowel|Subject), data=formant_data_5, REML=FALSE)
phon_acco.model15 = lmer(normF1$F1_15 ~ Gender + Context*Vowel + Task + (1+Task+Context|Word) +
(1+Task+Context*Vowel|Subject), data=formant_data_5, REML=FALSE)
phon_acco.model35 = lmer(normF1$F1_35 ~ Gender + Context*Vowel + Task + (1+Task+Context|Word) +
(1+Task+Context*Vowel|Subject), data=formant_data_5, REML=FALSE)
phon_acco.model45 = lmer(normF1$F1_45 ~ Gender + Context*Vowel + Task + (1+Task+Context|Word) +
(1+Task+Context*Vowel|Subject), data=formant_data_5, REML=FALSE)
phon_acco.model25 = lmer(normF1$F1_25 ~ Gender + Context*Vowel + Task + (1+Task+Context|Word) +
(1+Task+Context*Vowel|Subject), data=formant_data_5, REML=FALSE)
stargazer(phon_acco.model5,phon_acco.model15,phon_acco.model25,phon_acco.model35,phon_acco.model45,
order = c("Constant","Gendermale"),out = 'stargazer_F1_final.tex')
null.model25 = lmer(normF1$F1_25 ~ Gender + Task + (1+Task+Context|Word) +
(1+Task+Context*Vowel|Subject), data=formant_data_5, REML=FALSE)
null.model35 = lmer(normF1$F1_35 ~ Gender + Task + (1+Task+Context|Word) +
(1+Task+Context*Vowel|Subject), data=formant_data_5, REML=FALSE)
af115 <- anova(phon_acco.model15,null.model15)
af125 <- anova(phon_acco.model25,null.model25)
af135 <- anova(phon_acco.model35,null.model35)
af145 <- anova(phon_acco.model45,null.model45)
stargazer(af15,af115,af125,af135,af145, out = 'anova_f1.tex')
f2null.model5 = lmer(normF2$F2_5 ~ Gender + Task + (1+Task+Context|Word) +
(1+Task+Context*Vowel|Subject), data=formant_data_5, REML=FALSE)
f2null.model15 = lmer(normF2$F2_15 ~ Gender + Task + (1+Task+Context|Word) +
(1+Task+Context*Vowel|Subject), data=formant_data_5, REML=FALSE)
null.model45 = lmer(normF1$F1_45 ~ Gender + Task + (1+Task+Context|Word) +
(1+Task+Context*Vowel|Subject), data=formant_data_5, REML=FALSE)
f2phon_acco.model35 = lmer(normF2$F2_35 ~ Gender + Context*Vowel + Task + (1+Task+Context|Word) +
(1+Task+Context*Vowel|Subject), data=formant_data_5, REML=FALSE)
f2phon_acco.model45 = lmer(normF2$F2_45 ~ Gender + Context*Vowel + Task + (1+Task+Context|Word) +
(1+Task+Context*Vowel|Subject), data=formant_data_5, REML=FALSE)
stargazer(f2phon_acco.model5, f2phon_acco.model15, f2phon_acco.model25, f2phon_acco.model35, f2phon_acco.model45,
order = c("Constant","Gendermale","Vowel\vt","Contexte","Tasks"),out = 'stargazer_F2_final.tex')
# ANOVAs:
af15 <- anova(phon_acco.model5,null.model5)
## output for writeup: F2
f2phon_acco.model5 = lmer(normF2$F2_5 ~ Gender + Context*Vowel + Task + (1+Task+Context|Word) +
(1+Task+Context*Vowel|Subject), data=formant_data_5, REML=FALSE)
f2phon_acco.model15 = lmer(normF2$F2_15 ~ Gender + Context*Vowel + Task + (1+Task+Context|Word) +
(1+Task+Context*Vowel|Subject), data=formant_data_5, REML=FALSE)
f2phon_acco.model25 = lmer(normF2$F2_25 ~ Gender + Context*Vowel + Task + (1+Task+Context|Word) +
(1+Task+Context*Vowel|Subject), data=formant_data_5, REML=FALSE)
f2null.model25 = lmer(normF2$F2_25 ~ Gender + Task + (1+Task+Context|Word) +
(1+Task+Context*Vowel|Subject), data=formant_data_5, REML=FALSE)
f2null.model35 = lmer(normF2$F2_35 ~ Gender + Task + (1+Task+Context|Word) +
(1+Task+Context*Vowel|Subject), data=formant_data_5, REML=FALSE)
f2null.model45 = lmer(normF2$F2_45 ~ Gender + Task + (1+Task+Context|Word) +
(1+Task+Context*Vowel|Subject), data=formant_data_5, REML=FALSE)
# ANOVAs:
af25 <- anova(phon_acco.model5,null.model5)
